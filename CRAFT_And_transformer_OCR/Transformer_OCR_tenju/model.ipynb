{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import math, copy\n",
    "from torch.autograd import Variable\n",
    "from torchvision import datasets, models, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn\n",
    "seaborn.set_context(context=\"talk\")\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderDecoder(nn.Module):\n",
    "    def __init__(self, encoder, decoder, src_embed, tgt_embed, generator):\n",
    "        super(EncoderDecoder, self).__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.src_embed = src_embed\n",
    "        self.tgt_embed = tgt_embed\n",
    "        self.generator = generator\n",
    "    \n",
    "    def forward(self, src, tgt, src_mask, tgt_mask):\n",
    "        return self.decode(self.encoder(src, src_mask), src_mask, tgt, tgt_mask)\n",
    "    \n",
    "    def encode(self, src, src_mask):\n",
    "        return self.encoder(self.src_embed(src), src_mask)\n",
    "    \n",
    "    def decode(self, memory, src_mask, tgt, tgt_mask):\n",
    "        return self.decoder(self.tgt_embed(tgt), memory, src_mask, tgt_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    \"기본 선형 + 소프트맥스 정의\"\n",
    "    def __init__(self, d_model, vocab):\n",
    "        super(Generator, self).__init__()\n",
    "        self.proj = nn.Linear(d_model, vocab)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return F.log_softmax(self.proj(x), dim=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clones(module, N):\n",
    "    return nn.ModuleList([copy.deepcopy(module) for _ in range(N)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, layer, N):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.layers = clones(layer, N)\n",
    "        self.norm = LayerNorm(layer.size)\n",
    "        \n",
    "    def forward(self, x, mask):\n",
    "        for layer in self.layers:\n",
    "            x = layer(x, mask)\n",
    "        return self.norm(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LayerNorm(nn.Module):\n",
    "    def __init__(self, features, eps=1e-6):\n",
    "        super(LayerNorm, self).__init__()\n",
    "        self.a_2 = nn.Parameter(torch.ones(features))\n",
    "        self.b_2 = nn.Parameter(torch.zeros(features))\n",
    "        self.eps = eps\n",
    "        \n",
    "    def forward(self, x):\n",
    "        mean = x.mean(-1, keepdim=True)\n",
    "        std = x.std(-1, keepdim=True)\n",
    "        return self.a_2 * (x -mean) / (std + self.eps) + self.b_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "각 Sublayer의 output은 LayerNorm(x+Sublayer(x), 여기서 Sublayer(x)는 Sublayer 자체에 의해 구현되는 기능입니다. Sublayer input에 추가되고 normalized 전에 각 Sublayer의 output에 Drop out을 적용합니다.\n",
    "\n",
    "이러한 residual connections을 용이하게 하기 위해 embedding layer와 마찬가지로 모델에 모든 sub-layer 차원 d = 512의 출력을 생성합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SublayerConnection(nn.Module):\n",
    "    def __init__(self, size, dropout):\n",
    "        super(SublayerConnection, self).__init__()\n",
    "        self.norm = LayerNorm(size)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, x, sublayer):\n",
    "        return x + self.dropout(sublayer(self.norm(x)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "각 layer는 2개의 sub-lyaers를 가지고 있다. <br>\n",
    "첫번째, multi-head self-attention mechanism, <br>\n",
    "두번째, simple, position-wise fully connected feed-forward network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderLayer(nn.Module):\n",
    "    def __init__(self, size, self_attn, feed_forward, dropout):\n",
    "        super(EncoderLayer, self).__init__()\n",
    "        self.self_attn = self_attn\n",
    "        self.feed_forward = feed_forward\n",
    "        self.sublayer = clones(SublayerConnection(size, dropout), 2)\n",
    "        self.size = size\n",
    "        \n",
    "    def forward(self, x, mask):\n",
    "        x = self.sublayer[0](x, lambda x: self.self_attn(x, x, x, mask))\n",
    "        return self.sublayer[1](x, self.feed_forward) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, layer, N):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.layers = clones(layer, N)\n",
    "        self.norm = LayerNorm(layer.size)\n",
    "    \n",
    "    def forward(self, x, memory, src_mask, tgt_mask):\n",
    "        for layer in self.layers:\n",
    "            x = layer(x, memory, src_mask, tgt_mask)\n",
    "        return self.norm(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderLayer(nn.Module):\n",
    "    def __init__(self, size, self_attn, src_attn, feed_forward, dropout):\n",
    "        super(DecoderLayer, self).__init__()\n",
    "        self.size = size\n",
    "        self.self_attn = self_attn\n",
    "        self.src_attn = src_attn\n",
    "        self.feed_forward = feed_forward\n",
    "        self.sublayer = clones(SublayerConnection(size, dropout), 3)\n",
    "        \n",
    "    def forward(self, x, memory, src_mask, tgt_mask):\n",
    "        m = memory\n",
    "        x = self.sublayer[0](x, lambda x: self.self_attn(x, x, x, tgt_mask))\n",
    "        x = self.sublayer[1](x, lambda x: self.src_attn(x, m, m, src_mask))\n",
    "        return self.sublayer[2](x, self.feed_forward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def subsequent_mask(size):\n",
    "    attn_shape = (1, size, size)\n",
    "    subsequent_mask = np.triu(np.ones(attn_shape), k=1).astype('uint8')\n",
    "    return torch.from_numpy(subsequent_mask) == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(5,5))\n",
    "plt.imshow(subsequent_mask(50)[0])\n",
    "None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
